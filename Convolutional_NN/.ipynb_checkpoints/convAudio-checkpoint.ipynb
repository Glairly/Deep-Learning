{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from torchvision import transforms ,datasets\n",
    "\n",
    "import helper\n",
    "import waveLoader as wl\n",
    "import importlib\n",
    "importlib.reload(helper)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    input_size = 100\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "            # fc = fully connected\n",
    "        self.conv1 = nn.Conv2d(1,6, 5).cuda()\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5).cuda()\n",
    "        self.pool = nn.MaxPool2d(2,2).cuda()\n",
    "        \n",
    "        self.fc1 = nn.Linear(1,120).cuda()\n",
    "        self.fc2 = nn.Linear(120,84).cuda()\n",
    "        self.out = nn.Linear(84,2).cuda()\n",
    "        \n",
    "    def convs(self,x):\n",
    "#         print(x.size()[0])\n",
    "        batch_size = x.size()[0]\n",
    "        x = x.view(batch_size,1,self.input_size,self.input_size)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "#         print(x.size())\n",
    "        size = x.size()[1] * x.size()[2] * x.size()[3]\n",
    "#         print(size)\n",
    "        x = x.view(batch_size,size)\n",
    "        self.fc1 = nn.Linear(size,120).cuda()\n",
    "        return x\n",
    "               \n",
    "    def dense(self,x):\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self,x,input_size = 100):\n",
    "        self.input_size = input_size\n",
    "        x = self.convs(x)\n",
    "        x = self.dense(x)\n",
    "        \n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class Audio():\n",
    "    path = \"data/Audio/train/\"\n",
    "    pathT = \"data/Audio/train/\"\n",
    "    sub  = {\"cats\":0,\"dogs\":1}\n",
    "    trainset = []\n",
    "    testset = []\n",
    "    batch_size = 4\n",
    "    input_size = 300\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.net = Net().to(device)\n",
    "        return\n",
    "    \n",
    "    def compress(self,x,size = 100):\n",
    "        arrSize = x.size()[0]\n",
    "        comSize = int(math.ceil(arrSize/(size**2)))\n",
    "        ind = 0\n",
    "        compressed = []\n",
    "        while(ind < arrSize):\n",
    "            z = x[ind:ind+comSize].sum()/comSize\n",
    "            compressed.append(z)\n",
    "            ind+=comSize\n",
    "         \n",
    "        if (len(compressed) > size**2):\n",
    "            compressed = compressed[:size**2]\n",
    "        elif (len(compressed) < size**2):\n",
    "             for i in range((size**2)-len(compressed)):\n",
    "                compressed.append(0)\n",
    "                \n",
    "        compressed = torch.FloatTensor(compressed)\n",
    "        return compressed.view(-1,size),compressed\n",
    "    \n",
    "    def cut(self,x,size = 100):\n",
    "        if(size%2 != 0):\n",
    "            raise Exception(\"Invalid Size, Must be even size\")\n",
    "        _size = size\n",
    "        self.input_size = size\n",
    "        size = size**2 \n",
    "        x_size = x.size()[0]\n",
    "        compressed = []\n",
    "        half = size/2\n",
    "        half_x = x_size/2\n",
    "        while(half_x + half > x_size and half_x >= 0 ):\n",
    "           # print(half_x + half)\n",
    "            half_x -= 1\n",
    "        \n",
    "        if (half_x == -1 or half_x - half < 0):\n",
    "            raise Exception(\"Input out of Bound, Input Size cannot be cut \",x_size/2,half)\n",
    "            \n",
    "        left = int(half_x - half)\n",
    "        right = int(half_x + half)\n",
    "#         print(left,right,x)\n",
    "        compressed = x[left:right].tolist()\n",
    "        compressed = torch.FloatTensor(compressed)\n",
    "#         print(compressed.size())\n",
    "        return compressed.view(-1,_size),compressed\n",
    "    \n",
    "    def loadData(self,cut = 300):\n",
    "        for label in self.sub:\n",
    "            root = self.path+str(label)\n",
    "            for i in tqdm(os.listdir(root)):\n",
    "                try:\n",
    "                    path = root+\"/\"+str(i)\n",
    "                    frame,framerate = wl.readwavefile(path)\n",
    "                    frame = torch.from_numpy(frame)\n",
    "#                     print(frame)\n",
    "#                     plt.plot(frame)\n",
    "#                     plt.show()\n",
    "#                     print(len(frame))\n",
    "    #                 frame,_ = self.compress(frame,50)\n",
    "                    frame,_ = self.cut(frame,cut)\n",
    "#                     plt.plot(_)\n",
    "#                     plt.show()\n",
    "\n",
    "#                     print(frame.size())\n",
    "\n",
    "                    self.trainset.append((frame,self.sub[str(label)]))\n",
    "                except :\n",
    "                    pass\n",
    "        \n",
    "        self.trainset = torch.utils.data.DataLoader(self.trainset, \n",
    "                                       batch_size=self.batch_size,\n",
    "                                       shuffle=True,num_workers=2)\n",
    "        torch.save(self.trainset,\"temp/audio.pt\")\n",
    "    \n",
    "    def loadTest(self,cut = 300):\n",
    "        for label in self.sub:\n",
    "            root = self.pathT+str(label)\n",
    "            for i in tqdm(os.listdir(root)):\n",
    "                try:\n",
    "                    path = root+\"/\"+str(i)\n",
    "                    frame,framerate = wl.readwavefile(path)\n",
    "                    frame = torch.from_numpy(frame)\n",
    "#                     print(frame)\n",
    "#                     plt.plot(frame)\n",
    "#                     plt.show()\n",
    "#                     print(len(frame))\n",
    "    #                 frame,_ = self.compress(frame,50)\n",
    "                    frame,_ = self.cut(frame,cut)\n",
    "#                     plt.plot(_)\n",
    "#                     plt.show()\n",
    "\n",
    "#                     print(frame.size())\n",
    "\n",
    "                    self.testset.append((frame,self.sub[str(label)]))\n",
    "                except :\n",
    "                    pass\n",
    "        \n",
    "        self.testset = torch.utils.data.DataLoader(self.testset, \n",
    "                                       batch_size=self.batch_size,\n",
    "                                       shuffle=True,num_workers=2)\n",
    "        torch.save(self.testset,\"temp/audio_test.pt\")\n",
    "    \n",
    "    def load(self,path):\n",
    "        self.trainset = torch.load(path)\n",
    "    \n",
    "    def loadT(self,path):\n",
    "        self.testset = torch.load(path)\n",
    "    \n",
    "    def train(self,epochs=3):\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(self.net.parameters(), lr=0.001, momentum=0.9)\n",
    "        trainset = self.trainset \n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            for data in self.trainset :\n",
    "#                 try:\n",
    "                    x,y = data\n",
    "                    x,y = x.to(device),y.to(device)\n",
    "                    self.net.zero_grad() \n",
    "                    output = self.net.forward(x,input_size = self.input_size)\n",
    "                    loss = criterion(output, y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "#                 except Exception as e:\n",
    "#                     print(e)\n",
    "#                     break\n",
    "                \n",
    "            print(loss)\n",
    "            self.test(self.trainset)\n",
    "        \n",
    " \n",
    " \n",
    "    def test(self,x): # test\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        trainset = x\n",
    "        co = 0\n",
    "        with torch.no_grad():\n",
    "            for data in trainset:\n",
    "                co+=1\n",
    "                if(co == 20): \n",
    "                    break\n",
    "                x,y = data\n",
    "                x,y = x.to(device),y.to(device)\n",
    "               # print(\"input\",x.size())\n",
    "                output = self.net.forward(x,input_size = self.input_size)\n",
    "               # print(output,y)\n",
    "                for idx,i in enumerate(output):\n",
    "                    if torch.argmax(i) == y[idx]:\n",
    "                        correct += 1\n",
    "                    total += 1\n",
    "        print(\"Accuracy : \",round(correct/total,3)*100,\"%\")\n",
    "        return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 150.00it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 85/85 [00:00<00:00, 206.59it/s]\n"
     ]
    }
   ],
   "source": [
    "aud = Audio()\n",
    "aud.loadData(cut = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud.load(\"temp/audio.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6808, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:08<01:15,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  82.89999999999999 %\n",
      "tensor(0.7396, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:16<01:06,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  82.89999999999999 %\n",
      "tensor(0.5256, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:25<01:00,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  82.89999999999999 %\n",
      "tensor(0.4755, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:33<00:50,  8.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  84.2 %\n",
      "tensor(0.8444, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:43<00:43,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  82.89999999999999 %\n",
      "tensor(0.8740, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:51<00:34,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  82.89999999999999 %\n",
      "tensor(0.3766, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [00:59<00:25,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  82.89999999999999 %\n",
      "tensor(0.6390, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [01:07<00:16,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  84.2 %\n",
      "tensor(0.9529, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [01:14<00:08,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  84.2 %\n",
      "tensor(0.6459, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:22<00:00,  8.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  82.89999999999999 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aud.train(epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 263.84it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 85/85 [00:00<00:00, 340.91it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Audio' object has no attribute 'testset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-239dca6be9d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maud\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadTest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-b4c1211f5fbf>\u001b[0m in \u001b[0;36mloadTest\u001b[1;34m(self, cut)\u001b[0m\n\u001b[0;32m    107\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         self.testset = torch.utils.data.DataLoader(self.testset, \n\u001b[0m\u001b[0;32m    110\u001b[0m                                        \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m                                        shuffle=True,num_workers=2)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Audio' object has no attribute 'testset'"
     ]
    }
   ],
   "source": [
    "aud.loadTest()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud.loadT(\"temp/audio_test.pt\")\n",
    "aud.test(aud.testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-GPU2",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
